{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd3daf6",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3efdb",
   "metadata": {},
   "source": [
    "Цель задания: определить уровень воды рек на постах гидрологического контроля, используя данные метеосводок и ежедневных наблюдений за 2008-2017 года."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47104e89",
   "metadata": {},
   "source": [
    "### Проверка и установка рабочей директории, должен быть корень проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff8b31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Kuroha\\\\source\\\\repos_py\\\\bauman_final_project\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3645e379",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuroha\\source\\repos_py\\bauman_final_project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945d520",
   "metadata": {},
   "source": [
    "### Загрузка датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1335de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\bauman_final_project\\lib\\site-packages\\pandas\\__init__.py:138\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, testing, tseries\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     ExcelFile,\n\u001b[0;32m    141\u001b[0m     ExcelWriter,\n\u001b[0;32m    142\u001b[0m     read_excel,\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# parsers\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     read_csv,\n\u001b[0;32m    145\u001b[0m     read_fwf,\n\u001b[0;32m    146\u001b[0m     read_table,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# pickle\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     read_pickle,\n\u001b[0;32m    149\u001b[0m     to_pickle,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# pytables\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     HDFStore,\n\u001b[0;32m    152\u001b[0m     read_hdf,\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# sql\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     read_sql,\n\u001b[0;32m    155\u001b[0m     read_sql_query,\n\u001b[0;32m    156\u001b[0m     read_sql_table,\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     read_clipboard,\n\u001b[0;32m    159\u001b[0m     read_parquet,\n\u001b[0;32m    160\u001b[0m     read_orc,\n\u001b[0;32m    161\u001b[0m     read_feather,\n\u001b[0;32m    162\u001b[0m     read_gbq,\n\u001b[0;32m    163\u001b[0m     read_html,\n\u001b[0;32m    164\u001b[0m     read_xml,\n\u001b[0;32m    165\u001b[0m     read_json,\n\u001b[0;32m    166\u001b[0m     read_stata,\n\u001b[0;32m    167\u001b[0m     read_sas,\n\u001b[0;32m    168\u001b[0m     read_spss,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _json_normalize \u001b[38;5;28;01mas\u001b[39;00m json_normalize\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\bauman_final_project\\lib\\site-packages\\pandas\\io\\api.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipboards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_clipboard\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ExcelFile,\n\u001b[0;32m     10\u001b[0m     ExcelWriter,\n\u001b[0;32m     11\u001b[0m     read_excel,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeather_format\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_feather\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgbq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_gbq\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\bauman_final_project\\lib\\site-packages\\pandas\\io\\excel\\__init__.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_writer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_xlsxwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XlsxWriter \u001b[38;5;28;01mas\u001b[39;00m _XlsxWriter\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_xlwt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XlwtWriter \u001b[38;5;28;01mas\u001b[39;00m _XlwtWriter\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_excel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcelWriter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcelFile\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m register_writer(_OpenpyxlWriter)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1423\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1395\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1522\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(dataset_name):\n",
    "    path = get_filepath(dataset_name, is_raw=True)\n",
    "    return pd.read_csv(path, index_col=['uid', 'date'], parse_dates=['date'])\n",
    "\n",
    "weather_df = open_dataset(DATA_WEATHER)\n",
    "water_lvl_df = open_dataset(DATA_WATER_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaaea8f",
   "metadata": {},
   "source": [
    "### Информация о датасетах:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b7c0",
   "metadata": {},
   "source": [
    "#### water_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43fd84",
   "metadata": {},
   "source": [
    "В датасете представлены замеры уровня воды для постов гидрологического контроля с сайта АИС ГМВО."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_lvl_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bedc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "water_lvl_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_lvl_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b805121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "water_lvl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a52180",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_lvl_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3955952",
   "metadata": {},
   "source": [
    "#### weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e983941",
   "metadata": {},
   "source": [
    "В **weather** содержится погода на период 2008-2017 для обучения моделей, в котором есть следующие столбцы:\n",
    "- индекс **uid** - идентификационный номер поста гидрологического контроля с сайта АИС ГМВО.\n",
    "- индекс **date** - дата замера\n",
    "- **temperature** - температура\n",
    "- **cloud** - облачность\n",
    "- **weather** - погодное явление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653776f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716b37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b08b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb02029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6927816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95175c1a",
   "metadata": {},
   "source": [
    "***\n",
    "### Объединение тренировочных наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f2510",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = weather_df.join(water_lvl_df)\n",
    "df.head(), df.info(), df.shape, weather_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e9031",
   "metadata": {},
   "source": [
    "Количество строк до объединения **weather_df** и после осталось тем же."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774950a",
   "metadata": {},
   "source": [
    "### Работа с пропусками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9752b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Размерность water_lvl_df: {water_lvl_df.shape}')\n",
    "print(f'Размерность weather_df: {weather_df.shape}')\n",
    "print(f'Размерность df: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf8552",
   "metadata": {},
   "source": [
    "В датасете **weather_df** есть строки за каждый день по каждому посту, однако в данных есть пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b89fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf20f",
   "metadata": {},
   "source": [
    "Рассмотрим данные с поста **9518** за период с **2016-09-17** по **2016-09-21**, где отсутствуют метео-данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ed6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_start_date = '2016-09-17'\n",
    "test_end_date   = '2016-09-21'\n",
    "df.query('uid == 9518 and date >= @test_start_date and date <= @test_end_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbc88d",
   "metadata": {},
   "source": [
    "Посмотрим, в скольких строках отсутствуют данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027c9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f289a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Процент строк с отсутствующими данными об облачности: {df[\"cloud\"].isnull().sum() / df.shape[0] * 100:.2f}%')\n",
    "print(f'Процент строк с отсутствующими данными об уровне воды: {df[\"water_level\"].isnull().sum() / df.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8a842",
   "metadata": {},
   "source": [
    "Т.к. строк с частичными данными меньше 5%, то удалим их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbbbd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004eb761",
   "metadata": {},
   "source": [
    "Чтобы в дальнейшем работать с текущими значениями внутри мультииндекса (uid и дата замера), создадим столбец с новым индексом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aefd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea30a1e3",
   "metadata": {},
   "source": [
    "### Обработка признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068a699",
   "metadata": {},
   "source": [
    "#### Latitude (широта) и Longitude (долгота):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57aa0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_col_info(column):\n",
    "    print(f'''describe:\n",
    "{column.describe(datetime_is_numeric=True)}\n",
    "{\"-\" * 80}\n",
    "unique:\n",
    "{column.unique()}\n",
    "{\"-\" * 80}\n",
    "nunique:\n",
    "{column.nunique()}\n",
    "{\"-\" * 80}\n",
    "value_count:\n",
    "{column.value_counts()}''')\n",
    "\n",
    "print_col_info(df['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1f919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_col_info(df['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870f6a7",
   "metadata": {},
   "source": [
    "Всего уникальных локаций - 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_lat = range(int(df['latitude'].min()), int(df['latitude'].max() + 2))\n",
    "range_long = range(int(df['longitude'].min()), int(df['longitude'].max() + 2))\n",
    "\n",
    "ax = sns.scatterplot(data=df, x='latitude', y='longitude')\n",
    "ax.set(xlabel='Долгота', ylabel='Широта', title='Локации постов наблюдений')\n",
    "ax.set_xticks(range_lat)\n",
    "ax.set_yticks(range_long)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40310961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Разброс долготы: {df['longitude'].min()} {df['longitude'].max()}\")\n",
    "print(f\"Разброс широты: {df['latitude'].min()} {df['latitude'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ссылка на Яндекс.Карты с выделенным регионом: ' +\n",
    "f\"https://yandex.ru/maps/?ll={(df['longitude'].max() + df['longitude'].min()) / 2},\" +\n",
    "f\"{(df['latitude'].max() + df['latitude'].min()) / 2}\" +  # начальные координаты для показа, покажем центр\n",
    "f\"&rl={df['longitude'].min()},{df['latitude'].min()}\" +  # координаты первой точки выделения\n",
    "f\"~{df['longitude'].max() - df['longitude'].min()},0\" +  # вторая точка, в виде смещения относительно начальной\n",
    "f\"~0,{df['latitude'].max() - df['latitude'].min()}\" +\n",
    "f\"~{df['longitude'].min() - df['longitude'].max()},0\" +\n",
    "f\"~0,{df['latitude'].min() - df['latitude'].max()}\" +\n",
    "f\"&z=5\")  # приближение на карте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe87fbd",
   "metadata": {},
   "source": [
    "![Регион на Яндекс.Картах](images/yandex_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d6cf9d",
   "metadata": {},
   "source": [
    "Данные признаки будут нормализованы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338786b1",
   "metadata": {},
   "source": [
    "#### Cloud (облачность):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5d79d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_col_info(df['cloud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec80a7d",
   "metadata": {},
   "source": [
    "Облачность может быть следующей:\n",
    "- **sun** - ясно\n",
    "- **sunс** - малооблачно\n",
    "- **suncl** - облачно\n",
    "- **dull** - пасмурно\n",
    "\n",
    "Здесь прослеживается порядок - от ясного неба к пасмурному, поэтому для кодирования данного упорядоченного признака необходимо использовать метод Label Encoder.\n",
    "\n",
    "Реализация данного метода в sklearn перед кодированием [сортирует уникальные признаки в алфавитном порядке](https://github.com/scikit-learn/scikit-learn/blob/f3f51f9b611bf873bd5836748647221480071a87/sklearn/preprocessing/_label.py#L799), в результате чего будет нарушен порядок: **dull** будет закодирован как 0, **sun** - как 1, **sunс** - 2, **suncl** - 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28085a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['cloud'] = df['cloud'].map({'sun': 0, 'sunc': 1, 'suncl': 2, 'dull': 3})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22221a",
   "metadata": {},
   "source": [
    "#### uid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_col_info(df['uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20aa8b7",
   "metadata": {},
   "source": [
    "Представляет собой идентификационный номер поста гидрологического контроля в базе данных сайта АИС ГМВО.\n",
    "\n",
    "Задачу прогнозирования можно решить двумя способами:\n",
    "1. Разработать одну модель для всех постов. Это имеет смысл, т.к. посты географически расположены близко друг к другу, а также замеряют уровень воды одной реки.\n",
    "2. Разработать индивидуальные модели для всех постов.\n",
    "    \n",
    "Будет реализован первый вариант, т.к. недостаточно данных наблюдений по каждому посту. UID постов будут закодированы как категориальные данные, используя One Hot Encoding, однако предварительно нужно посмотреть, были ли случаи использования метео-данных по запасной локации - если их не было, то данные UIDы кодировать не нужно, т.к. их однозначно можно определить по координатам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3dc4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ignore_uids = df.groupby('uid').filter(lambda x: (x.is_fallback_data == 0).all())['uid'].unique()\n",
    "ignore_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ff56d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "replace_map = dict(zip(ignore_uids, (None for x in range(len(ignore_uids)))))\n",
    "replace_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['uid_copy'] = df['uid']  # копия uid для визуализации, будет удалена перед сохранением датасета\n",
    "df['uid_copy'] = df['uid_copy'].replace(replace_map)\n",
    "print_col_info(df['uid_copy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e5c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode_uid(df_target):\n",
    "    encoder = OneHotEncoder()\n",
    "    df_uid = pd.DataFrame(encoder.fit_transform(df[['uid_copy']]).toarray())\n",
    "    df_uid = df_uid.add_prefix('uid_')  # префикс для визуального определения признака\n",
    "    df_uid = df_uid.astype('category')  # конвертация в категориальный тип данных\n",
    "    return df_target.join(df_uid)\n",
    "\n",
    "df = encode_uid(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c498dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('uid_copy.isnull()').head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ab4e4",
   "metadata": {},
   "source": [
    "None закодировался в uid_15, удалим столбцы uid_copy и uid_15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['uid_copy', 'uid_15'], axis=1)\n",
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2167f",
   "metadata": {},
   "source": [
    "#### Date (дата):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_col_info(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bace6",
   "metadata": {},
   "source": [
    "Представляет собой день наблюдений. Данное значение можно закодировать как:\n",
    "1. Год - категориальный признак, используя метод Label Encoder (есть порядок: 2008 год был раньше, чем 2017)\n",
    "2. Номер дня в году - цикличный признак.\n",
    "\n",
    "Значения дня представляет собой следующий график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5858d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(df['date'].dt.day[:500])\n",
    "plt.xlabel('Номер значения')\n",
    "plt.ylabel('День')\n",
    "plt.title('Значения дня')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d504043",
   "metadata": {},
   "source": [
    "Данные являются зацикленными, т.к. 31 день в месяце отличается от следующего 1-го дня лишь на одну единицу, а не на 30. Значение дня в году [можно представить в виде двух функций](http://blog.davidkaleko.com/feature-engineering-cyclical-features.html):\n",
    "\n",
    "$x_{sin} = \\sin(\\frac{2 * \\pi * x}{\\max(x)})$\n",
    "\n",
    "$x_{cos} = \\cos(\\frac{2 * \\pi * x}{\\max(x)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65ede7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_day = 70\n",
    "np.sin(2 * np.pi * test_day/365.0), np.cos(2 * np.pi * test_day/365.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a563475",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df = df[0:500]['date']\n",
    "total_years = np.where(test_df.dt.is_leap_year, 366, 365)\n",
    "test_arr = test_df.dt.dayofyear\n",
    "test_sin = np.sin(2 * np.pi * test_arr / total_years)\n",
    "test_cos = np.cos(2 * np.pi * test_arr / total_years)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(test_sin, color='blue', label='sin')\n",
    "ax1.plot(test_cos, color='red', label='cos')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "# показ точек на графике за 300 дней\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.scatter(test_sin[:300], test_cos[:300])\n",
    "ax2.set_xlabel('sin')\n",
    "ax2.set_ylabel('cos')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119afbe3",
   "metadata": {},
   "source": [
    "Закодируем год и номер дня в году:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa6c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_years = np.where(df['date'].dt.is_leap_year, 366, 365)\n",
    "df['year'] = df['date'].dt.year\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['date'].dt.dayofyear / total_years)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['date'].dt.dayofyear / total_years)\n",
    "df[['date', 'year', 'day_sin', 'day_cos']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c513098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166dc08a",
   "metadata": {},
   "source": [
    "#### Weather (осадки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff75df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_col_info(df['weather'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414298a5",
   "metadata": {},
   "source": [
    "Под осадками может пониматься следующее:\n",
    "- **clear** - осадков не было\n",
    "- **rain** - дождь\n",
    "- **storm** - гроза\n",
    "- **snow** - снег\n",
    "\n",
    "Данный признак можно закодировать разными способами:\n",
    "1. Выделение признака **наличие осадков**: и дождь, и снег образовываются из капель воды, а грозы, как правило, сопровождаются сильным дождём;\n",
    "2. Объединение понятий \"гроза\" и \"дождь\", выделив 2 признака: **дождь** и **снег**;\n",
    "3. 3 признака: **дождь**, **гроза**, **снег**, т.к. бывают сухие грозы;\n",
    "4. В одном столбце будет указаны все осадки.\n",
    "\n",
    "Во всех случаях отсутствие осадков обозначается 0 во всех признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca32be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['weather_v1_precip'] = df['weather'].map({'clear': 0, 'rain': 1, 'storm': 1, 'snow': 1})\n",
    "\n",
    "df['weather_v2_rain'] = df['weather'].map({'clear': 0, 'rain': 1, 'storm': 1, 'snow': 0})\n",
    "\n",
    "# снег одинаково обозначается во 2 и 3 случаях\n",
    "df['weather_snow'] = df['weather'].map({'clear': 0, 'rain': 0, 'storm': 0, 'snow': 1})\n",
    "\n",
    "df['weather_v3_rain'] = df['weather'].map({'clear': 0, 'rain': 1, 'storm': 0, 'snow': 0})\n",
    "df['weather_v3_storm'] = df['weather'].map({'clear': 0, 'rain': 0, 'storm': 1, 'snow': 0})\n",
    "\n",
    "df['weather_v4'] = df['weather'].map({'clear': 0, 'rain': 1, 'storm': 2, 'snow': 3})\n",
    "\n",
    "df = df.drop(['weather'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62c7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc14ee",
   "metadata": {},
   "source": [
    "### Визуализация статистики:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df5435",
   "metadata": {},
   "source": [
    "Динамика изменения уровня воды на примере 6 постов наблюдений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb4b54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df = df[df['date'].dt.year == START_YEAR]\n",
    "\n",
    "palette = sns.color_palette(\"husl\", 28)\n",
    "sns.relplot(data=test_df, x='date', y='water_level', palette=palette,\n",
    "            hue='uid', kind=\"line\", aspect=2, legend='full').set(\n",
    "                title=f'Данные об уровнях воды всех постов за {START_YEAR} год')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada04fe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df = df[df['date'].dt.year == END_YEAR]\n",
    "\n",
    "palette = sns.color_palette(\"husl\", 28)\n",
    "sns.relplot(data=test_df, x='date', y='water_level', palette=palette,\n",
    "            hue='uid', kind=\"line\", aspect=2, legend='full').set(\n",
    "                title=f'Данные об уровнях воды всех постов за {END_YEAR} год')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed4a86",
   "metadata": {},
   "source": [
    "Не для всех постов есть данные за каждый день, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23cb29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_start_date = '2008-01-01'\n",
    "test_end_date = '2008-12-31'\n",
    "\n",
    "test_df = df.query('uid == 9421 and date >= @START_YEAR and date <= @test_end_date')\n",
    "test_df['date'].head(3), test_df['date'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc000b40",
   "metadata": {},
   "source": [
    "В 2008 году у поста 9421 (руч.без названия - факт.Кербо) есть показания от 1 мая до 25 ноября."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffb4d7",
   "metadata": {},
   "source": [
    "### Работа с аномалиями данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2c10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f098c6b",
   "metadata": {},
   "source": [
    "Рассмотрим зависимости признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b719bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['water_level', 'temperature', 'cloud', 'weather_v1_precip']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa592938",
   "metadata": {},
   "source": [
    "По графикам видно, что уровень воды снижается при температуре ниже 0 градуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc03162",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "sns.boxplot(data=df, x='latitude', ax=ax1).set(title='Широта')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "sns.boxplot(data=df, x='longitude', ax=ax2).set(title='Долгота')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "sns.histplot(data=df, x='latitude', ax=ax3).set(title='Широта')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "sns.histplot(data=df, x='longitude', ax=ax4).set(title='Долгота')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4a00f",
   "metadata": {},
   "source": [
    "Широта и долгота не имеет выбросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da58df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(df.corr(), annot=True, linewidths=.5, fmt=\".2f\", robust=True)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644316d4",
   "metadata": {},
   "source": [
    "Температура значительно отрицательно коррелирует с day_cos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e4b8e",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174ae92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=[np.number]).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cloud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d7920",
   "metadata": {},
   "source": [
    "Перед обучением модели необходимо привести нормализацию данных, а именно **temperature** и **year** (последний нужно закодировать с запасом на будущее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153275de",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_first_year = df.at[0, 'year']\n",
    "orig_first_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c3ea4",
   "metadata": {},
   "source": [
    "Изменяем год в первом записи для того, чтобы нормализация по году прошла с учётом будущих годов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fab359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.at[0, 'year'] = 2030\n",
    "df.at[0, 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20269707",
   "metadata": {},
   "source": [
    "Перед нормализацией данных необходимо сохранить минимальные и максимальные значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf45eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_min = df['uid'].min()\n",
    "uid_max = df['uid'].max()\n",
    "temperature_min = df['temperature'].min()\n",
    "temperature_max = df['temperature'].max()\n",
    "latitude_min = df['latitude'].min()\n",
    "latitude_max = df['latitude'].max()\n",
    "longitude_min = df['latitude'].min()\n",
    "longitude_max = df['latitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f7878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
    "\n",
    "columns_to_scale = ['temperature', 'cloud', 'year', 'latitude', 'longitude', 'uid']\n",
    "\n",
    "df[columns_to_scale] = minmax_scale(df[columns_to_scale])\n",
    "df[columns_to_scale]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f3ecd",
   "metadata": {},
   "source": [
    "Возвращаем обратно год в первой записи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1e2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.at[0, 'year'] = df.at[1, 'year']\n",
    "df.at[0, 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7506ea",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(get_filepath(DATA_PROCESSED_TRAIN, is_raw=False), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4f50c",
   "metadata": {},
   "source": [
    "Также сохраним пороговые значения для давления и скорости ветра для дальнейшего их применения к целевым данным, по которым будут производиться предсказания в дальнейшем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff771370",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_info = {\n",
    "    'year_first': START_YEAR,\n",
    "    'year_last': 2030,\n",
    "    'uid_min': uid_min,\n",
    "    'uid_max': uid_max,\n",
    "    'temperature_min': temperature_min,\n",
    "    'temperature_max': temperature_max,\n",
    "    'latitude_min': latitude_min,\n",
    "    'latitude_max': latitude_max,\n",
    "    'longitude_min': longitude_min,\n",
    "    'longitude_max': longitude_max,\n",
    "}\n",
    "write_data(DATA_NORMALIZATION, data=norm_info, is_raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
